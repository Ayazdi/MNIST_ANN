{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import spacy\n",
    "from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout, Flatten, Embedding, Dense\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import tensorflow.keras.utils\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace({'neutral':0, 'negative':-1, 'positive':1}, inplace=True)\n",
    "y = tensorflow.keras.utils.to_categorical(y, num_classes=3, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text  sentiment  \n",
       "0                    I`d have responded, if I were going          0  \n",
       "1                                               Sooo SAD         -1  \n",
       "2                                            bullying me         -1  \n",
       "3                                         leave me alone         -1  \n",
       "4                                          Sons of ****,         -1  \n",
       "...                                                  ...        ...  \n",
       "27476                                             d lost         -1  \n",
       "27477                                      , don`t force         -1  \n",
       "27478                          Yay good for both of you.          1  \n",
       "27479                         But it was worth it  ****.          1  \n",
       "27480  All this flirting going on - The ATG smiles. Y...          0  \n",
       "\n",
       "[27480 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-proccessing with SpaCy-transformer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"bert-base-uncased\"\n",
    "nlp = TransformersLanguage(trf_name=name, meta={\"lang\": \"en\"})\n",
    "nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
    "nlp.add_pipe(TransformersWordPiecer.from_pretrained(nlp.vocab, name))\n",
    "nlp.add_pipe(TransformersTok2Vec.from_pretrained(nlp.vocab, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text_data):\n",
    "    clean_X = []\n",
    "    for text in tqdm.tqdm(text_data):\n",
    "        doc = nlp(text)\n",
    "        word_id = doc._.trf_word_pieces\n",
    "        clean_X.append(word_id)\n",
    "    max_lenght = len(max(clean_X, key=len))    \n",
    "    word_vec_X = sequence.pad_sequences(clean_X, maxlen = max_lenght, padding='pre')\n",
    "    pd.DataFrame(word_vec_X).to_csv(\"word_vec_X.csv\", index=None)\n",
    "    return word_vec_X\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_X = preprocess(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_X = pd.read_csv('word_id.csv')\n",
    "word_vec_X = word_vec_X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(word_vec_X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-25 11:28:28--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.5.112, 2607:f8b0:4005:80b::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.5.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 408102251 (389M) [application/zip]\n",
      "Saving to: â€˜uncased_L-12_H-768_A-12.zipâ€™\n",
      "\n",
      "uncased_L-12_H-768_ 100%[===================>] 389.20M  76.8MB/s    in 4.9s    \n",
      "\n",
      "2020-05-25 11:28:36 (79.7 MB/s) - â€˜uncased_L-12_H-768_A-12.zipâ€™ saved [408102251/408102251]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  uncased_L-12_H-768_A-12.zip\n",
      "caution: filename not matched:  y\n"
     ]
    }
   ],
   "source": [
    "!unzip uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./uncased_L-12_H-768_A-12/\"\n",
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 112\n",
    "l_input_ids = tensorflow.keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "output = l_bert(l_input_ids)\n",
    "\n",
    "cls_out = tensorflow.keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\n",
    "cls_out = Dropout(0.5)(cls_out)\n",
    "\n",
    "logits = Dense(768, activation=\"tanh\")(cls_out)\n",
    "logits = Dropout(0.5)(logits)\n",
    "\n",
    "logits = Dense(units=3,activation=\"softmax\")(logits)\n",
    "\n",
    "model = tensorflow.keras.Model(inputs=l_input_ids, outputs=logits)\n",
    "model.build(input_shape=(None, max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 196 BERT weights from: ./uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7fa8b7219940> (prefix:bert_5). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
      "Unused weights from checkpoint: \n",
      "\tbert/embeddings/token_type_embeddings\n",
      "\tbert/pooler/dense/bias\n",
      "\tbert/pooler/dense/kernel\n",
      "\tcls/predictions/output_bias\n",
      "\tcls/predictions/transform/LayerNorm/beta\n",
      "\tcls/predictions/transform/LayerNorm/gamma\n",
      "\tcls/predictions/transform/dense/bias\n",
      "\tcls/predictions/transform/dense/kernel\n",
      "\tcls/seq_relationship/output_bias\n",
      "\tcls/seq_relationship/output_weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.load_stock_weights(l_bert, './uncased_L-12_H-768_A-12/bert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 112)]             0         \n",
      "_________________________________________________________________\n",
      "bert (BertModelLayer)        (None, 112, 768)          108890112 \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 768)               590592    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 2307      \n",
      "=================================================================\n",
      "Total params: 109,483,011\n",
      "Trainable params: 109,483,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tensorflow.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16488 samples, validate on 4122 samples\n",
      "Epoch 1/2\n",
      "16488/16488 [==============================] - 903s 55ms/sample - loss: 0.5329 - accuracy: 0.7444 - val_loss: 0.3824 - val_accuracy: 0.8404\n",
      "Epoch 2/2\n",
      "16488/16488 [==============================] - 887s 54ms/sample - loss: 0.3678 - accuracy: 0.8449 - val_loss: 0.3411 - val_accuracy: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faccd4cba20>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, epochs=2, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json, custom_objects={\"BertModelLayer\": bert.BertModelLayer})\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82      2800\n",
      "           1       0.89      0.86      0.87      2146\n",
      "           2       0.86      0.83      0.85      1924\n",
      "\n",
      "    accuracy                           0.85      6870\n",
      "   macro avg       0.85      0.84      0.85      6870\n",
      "weighted avg       0.85      0.85      0.85      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(Xtest, batch_size=64, verbose=0)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "ytest_bool = np.argmax(ytest, axis=1)\n",
    "print(classification_report(ytest_bool, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment of a new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_prediction(text):\n",
    "    doc = nlp(text)\n",
    "    word_id = doc._.trf_word_pieces\n",
    "    word_id = sequence.pad_sequences([word_id], maxlen = 112, padding='pre')\n",
    "    y_pred = loaded_model.predict(word_id, verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)[0]\n",
    "    \n",
    "    if y_pred_bool == 0:\n",
    "        prediction = \"neutral\"\n",
    "    if y_pred_bool == 1:\n",
    "        prediction = \"positive\"\n",
    "    else:\n",
    "        prediction = \"negative\"\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'I love spiced academy'\n",
    "sentiment_prediction(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
