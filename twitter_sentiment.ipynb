{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dropout, Flatten, Embedding, Flatten, Dense, LSTM\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import tensorflow.keras.utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "import en_trf_bertbaseuncased_lg\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace({'neutral':0, 'negative':-1, 'positive':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tensorflow.keras.utils.to_categorical(y, num_classes=3, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']\n"
     ]
    }
   ],
   "source": [
    "from spacy_transformers import TransformersLanguage, TransformersWordPiecer, TransformersTok2Vec\n",
    "\n",
    "name = \"bert-base-uncased\"\n",
    "nlp = TransformersLanguage(trf_name=name, meta={\"lang\": \"en\"})\n",
    "nlp.add_pipe(nlp.create_pipe(\"sentencizer\"))\n",
    "nlp.add_pipe(TransformersWordPiecer.from_pretrained(nlp.vocab, name))\n",
    "nlp.add_pipe(TransformersTok2Vec.from_pretrained(nlp.vocab, name))\n",
    "print(nlp.pipe_names)  # ['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27480/27480 [52:29<00:00,  8.72it/s]  \n"
     ]
    }
   ],
   "source": [
    "word_id =[]\n",
    "for i in tqdm.tqdm(X):\n",
    "    doc = nlp(i)\n",
    "    w = doc._.trf_word_pieces\n",
    "    word_id.append(w)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = spacy.load('en_trf_bertbaseuncased_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = len(max(word_id, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sequence.pad_sequences(clean_X, maxlen = max_lenght, padding='pre' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_id_2).to_csv(\"word_id.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_my_text(text):\n",
    "    lemmatized = []\n",
    "    text = text.lower()\n",
    "    tokens = nlp(text)\n",
    "    for word in tokens:\n",
    "        if not word.is_stop and word.is_alpha:            \n",
    "            lemmatized.append(word.lemma_)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess():\n",
    "    clean_X = []\n",
    "    for text in tqdm.tqdm(X):\n",
    "        lemmatized = clean_my_text(text)\n",
    "        if len(lemmatized) != 0:\n",
    "            join_string = ' '.join(lemmatized)\n",
    "            doc = nlp(join_string)\n",
    "            word_id = doc._.trf_word_pieces\n",
    "        else:\n",
    "            word_id = lemmatized        \n",
    "        clean_X.append(word_id)\n",
    "    max_lenght = len(max(clean_X, key=len))    \n",
    "    word_vec_X = sequence.pad_sequences(clean_X, maxlen = max_lenght, padding='pre')\n",
    "    pd.DataFrame(word_vec_X).to_csv(\"word_vec_spacy_trans.csv\", index=None)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27480/27480 [2:30:59<00:00,  3.03it/s]  \n"
     ]
    }
   ],
   "source": [
    "preproccess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>5838</td>\n",
       "      <td>2183</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>17111</td>\n",
       "      <td>2080</td>\n",
       "      <td>6517</td>\n",
       "      <td>3335</td>\n",
       "      <td>2624</td>\n",
       "      <td>5277</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>5795</td>\n",
       "      <td>18917</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>4357</td>\n",
       "      <td>2681</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>4124</td>\n",
       "      <td>7085</td>\n",
       "      <td>4149</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>4299</td>\n",
       "      <td>2272</td>\n",
       "      <td>1057</td>\n",
       "      <td>7573</td>\n",
       "      <td>3129</td>\n",
       "      <td>2439</td>\n",
       "      <td>3105</td>\n",
       "      <td>8984</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2486</td>\n",
       "      <td>16475</td>\n",
       "      <td>2015</td>\n",
       "      <td>4553</td>\n",
       "      <td>2047</td>\n",
       "      <td>11374</td>\n",
       "      <td>29003</td>\n",
       "      <td>10507</td>\n",
       "      <td>7159</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2342</td>\n",
       "      <td>2002</td>\n",
       "      <td>13306</td>\n",
       "      <td>5353</td>\n",
       "      <td>2729</td>\n",
       "      <td>15876</td>\n",
       "      <td>2078</td>\n",
       "      <td>22038</td>\n",
       "      <td>20348</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>4276</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>20661</td>\n",
       "      <td>2183</td>\n",
       "      <td>2012</td>\n",
       "      <td>2290</td>\n",
       "      <td>8451</td>\n",
       "      <td>8038</td>\n",
       "      <td>2100</td>\n",
       "      <td>24459</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9  ...    31     32     33     34    35  \\\n",
       "0      0  0  0  0  0  0  0  0  0  0  ...     0      0      0      0     0   \n",
       "1      0  0  0  0  0  0  0  0  0  0  ...     0      0    101  17111  2080   \n",
       "2      0  0  0  0  0  0  0  0  0  0  ...     0      0      0      0     0   \n",
       "3      0  0  0  0  0  0  0  0  0  0  ...     0      0      0      0     0   \n",
       "4      0  0  0  0  0  0  0  0  0  0  ...     0      0      0      0     0   \n",
       "...   .. .. .. .. .. .. .. .. .. ..  ...   ...    ...    ...    ...   ...   \n",
       "27475  0  0  0  0  0  0  0  0  0  0  ...   101   4299   2272   1057  7573   \n",
       "27476  0  0  0  0  0  0  0  0  0  0  ...  2486  16475   2015   4553  2047   \n",
       "27477  0  0  0  0  0  0  0  0  0  0  ...  2342   2002  13306   5353  2729   \n",
       "27478  0  0  0  0  0  0  0  0  0  0  ...     0      0      0      0     0   \n",
       "27479  0  0  0  0  0  0  0  0  0  0  ...   101  20661   2183   2012  2290   \n",
       "\n",
       "          36     37     38     39   40  \n",
       "0          0    101   5838   2183  102  \n",
       "1       6517   3335   2624   5277  102  \n",
       "2          0    101   5795  18917  102  \n",
       "3          0    101   4357   2681  102  \n",
       "4        101   4124   7085   4149  102  \n",
       "...      ...    ...    ...    ...  ...  \n",
       "27475   3129   2439   3105   8984  102  \n",
       "27476  11374  29003  10507   7159  102  \n",
       "27477  15876   2078  22038  20348  102  \n",
       "27478      0      0    101   4276  102  \n",
       "27479   8451   8038   2100  24459  102  \n",
       "\n",
       "[27480 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vec_X = pd.read_csv('word_vec_spacy_trans.csv')\n",
    "word_vec_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = ['']\n",
    "for text in clean_X:\n",
    "    for word in text:        \n",
    "        vocab_list.append(word)\n",
    "\n",
    "# takes care of the duplicates\n",
    "vocab_list = list(set(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [[1 ,2 ,3], [2], [2,2,2,2,2,2,2]]\n",
    "len(max(list, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_num = {}\n",
    "num_to_word = {}\n",
    "for i, word in enumerate(vocab_list):\n",
    "    num_to_word[i] = word\n",
    "    word_to_num[vocab_list[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_x = [[word_to_num[word] for word in text] for text in clean_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_X = sequence.pad_sequences(word_vec_x, maxlen = 22, padding='pre' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_x_series = pd.Series(clean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_x_series = clean_x_series.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>xo</td>\n",
       "      <td>hey</td>\n",
       "      <td>chick</td>\n",
       "      <td>u</td>\n",
       "      <td>alryt</td>\n",
       "      <td>u</td>\n",
       "      <td>dads</td>\n",
       "      <td>tmoro</td>\n",
       "      <td>sud</td>\n",
       "      <td>sumin</td>\n",
       "      <td>...</td>\n",
       "      <td>week</td>\n",
       "      <td>neva</td>\n",
       "      <td>dun</td>\n",
       "      <td>oot</td>\n",
       "      <td>week</td>\n",
       "      <td>lol</td>\n",
       "      <td>missed</td>\n",
       "      <td>ha</td>\n",
       "      <td>bye</td>\n",
       "      <td>hun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16149</th>\n",
       "      <td>av</td>\n",
       "      <td>ad</td>\n",
       "      <td>realy</td>\n",
       "      <td>gd</td>\n",
       "      <td>day</td>\n",
       "      <td>wiv</td>\n",
       "      <td>ciara</td>\n",
       "      <td>connolly</td>\n",
       "      <td>park</td>\n",
       "      <td>gate</td>\n",
       "      <td>...</td>\n",
       "      <td>new</td>\n",
       "      <td>brighton</td>\n",
       "      <td>fukin</td>\n",
       "      <td>funny</td>\n",
       "      <td>bt</td>\n",
       "      <td>sunburnt</td>\n",
       "      <td>luks</td>\n",
       "      <td>like</td>\n",
       "      <td>drivers</td>\n",
       "      <td>arm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1      2   3      4    5      6         7     8      9   ...  \\\n",
       "1234   xo  hey  chick   u  alryt    u   dads     tmoro   sud  sumin  ...   \n",
       "16149  av   ad  realy  gd    day  wiv  ciara  connolly  park   gate  ...   \n",
       "\n",
       "         12        13     14     15    16        17      18    19       20  \\\n",
       "1234   week      neva    dun    oot  week       lol  missed    ha      bye   \n",
       "16149   new  brighton  fukin  funny    bt  sunburnt    luks  like  drivers   \n",
       "\n",
       "        21  \n",
       "1234   hun  \n",
       "16149  arm  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_x_series.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_vec_X).to_csv(\"word_vec_X_trans.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_X = pd.read_csv('word_vec_X_trans.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_X = word_vec_X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(word_vec_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22735"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab_list) + 1 \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length=22))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(LSTM(1024))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(LSTM(512, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16488 samples, validate on 4122 samples\n",
      "Epoch 1/3\n",
      "16488/16488 [==============================] - 28s 2ms/sample - loss: 0.6935 - accuracy: 0.6562 - val_loss: 0.5241 - val_accuracy: 0.7196\n",
      "Epoch 2/3\n",
      "16488/16488 [==============================] - 23s 1ms/sample - loss: 0.4854 - accuracy: 0.7705 - val_loss: 0.4452 - val_accuracy: 0.7935\n",
      "Epoch 3/3\n",
      "16488/16488 [==============================] - 23s 1ms/sample - loss: 0.3969 - accuracy: 0.8261 - val_loss: 0.4614 - val_accuracy: 0.8017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99bdc462e8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain, epochs=3, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      8362\n",
      "           1       0.86      0.83      0.85      6477\n",
      "           2       0.81      0.81      0.81      5771\n",
      "\n",
      "    accuracy                           0.82     20610\n",
      "   macro avg       0.82      0.82      0.82     20610\n",
      "weighted avg       0.82      0.82      0.82     20610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(Xtrain, batch_size=64, verbose=0)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "ytrain_bool = np.argmax(ytrain, axis=1)\n",
    "print(classification_report(ytrain_bool, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.68      2755\n",
      "           1       0.78      0.73      0.76      2105\n",
      "           2       0.70      0.67      0.68      2010\n",
      "\n",
      "    accuracy                           0.70      6870\n",
      "   macro avg       0.71      0.70      0.71      6870\n",
      "weighted avg       0.70      0.70      0.70      6870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(Xtest, batch_size=64, verbose=0)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "ytest_bool = np.argmax(ytest, axis=1)\n",
    "print(classification_report(ytest_bool, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(word_id_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import BertModelLayer\n",
    "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
    "from bert.tokenization.bert_tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./uncased_L-12_H-768_A-12\"\n",
    "\n",
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 41\n",
    "l_input_ids      = tensorflow.keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "# l_token_type_ids = tensorflow.keras.layers.Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "# using the default token_type/segment id 0\n",
    "output = l_bert(l_input_ids) # output: [batch_size, max_seq_len, hidden_size]\n",
    "\n",
    "cls_out = tensorflow.keras.layers.Lambda(lambda seq: seq[:, 0, :])(output)\n",
    "cls_out = Dropout(0.5)(cls_out)\n",
    "# cls_out = BatchNormalization()(cls_out)\n",
    "logits = Dense(768, activation=\"tanh\")(cls_out)\n",
    "logits = Dropout(0.5)(logits)\n",
    "# logits = Dense(128, activation=\"relu\")(logits)\n",
    "# logits = Dropout(0.5)(logits)\n",
    "logits = Dense(units=3,activation=\"softmax\")(logits)\n",
    "\n",
    "\n",
    "model = tensorflow.keras.Model(inputs=l_input_ids, outputs=logits)\n",
    "model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "\n",
    "# model = tensorflowkeras.Model(inputs=l_input_ids, outputs=output)\n",
    "# model.build(input_shape=(None, max_seq_len))\n",
    "\n",
    "# provide a custom token_type/segment id as a layer input\n",
    "# output = l_bert([l_input_ids, l_token_type_ids])          # [batch_size, max_seq_len, hidden_size]\n",
    "# model = tensorflow.keras.Model(inputs=[l_input_ids, l_token_type_ids], outputs=output)\n",
    "# model.build(input_shape=[(None, max_seq_len), (None, max_seq_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_ckpt_file   = os.path.join(model_dir, \"bert_model.ckpt\")\n",
    "bert.load_stock_weights(l_bert, bert_ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tensorflow.keras.optimizers.Adam(1e-5), loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
